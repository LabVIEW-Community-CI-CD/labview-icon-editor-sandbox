name: Publish Ollama CPU image

on:
  workflow_dispatch:
    inputs:
      ref:
        description: "ollama git ref (tag/branch/sha) to build"
        required: false
        default: "main"
      tag:
        description: "image tag suffix (e.g., cpu-20250216; default cpu-latest)"
        required: false
        default: "cpu-latest"
  push:
    branches: [ main ]
    paths:
      - "docker/ollama/**"
      - ".github/workflows/ollama-image.yml"

permissions:
  contents: read
  packages: write

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    outputs:
      image_name: ${{ steps.names.outputs.image_name }}
      tag_suffix: ${{ env.TAG_SUFFIX }}
      preload_suffix: ${{ env.PRELOAD_SUFFIX }}
    env:
      OLLAMA_REF: ${{ github.event.inputs.ref || 'main' }}
      TAG_SUFFIX: ${{ github.event.inputs.tag || 'cpu-latest' }}
      SOURCE_DIR: /tmp/ollama-source
      PRELOAD_SUFFIX: cpu-preloaded-${{ github.event.inputs.tag || 'cpu-latest' }}
    steps:
      - name: Checkout repo (for Dockerfile)
        uses: actions/checkout@v4

      - name: Compute image name (lowercase owner)
        id: names
        run: |
          owner="${{ github.repository_owner }}"
          owner_lc="$(echo "$owner" | tr '[:upper:]' '[:lower:]')"
          echo "image_name=ghcr.io/${owner_lc}/ollama-local" >> "$GITHUB_OUTPUT"

      - name: Clone upstream ollama
        run: |
          git clone --depth 1 --branch "${OLLAMA_REF}" https://github.com/ollama/ollama.git "${SOURCE_DIR}"

      - name: Copy CPU Dockerfile into source
        run: |
          cp docker/ollama/Dockerfile "${SOURCE_DIR}/Dockerfile.cpu"

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ env.SOURCE_DIR }}
          file: ${{ env.SOURCE_DIR }}/Dockerfile.cpu
          push: true
          tags: |
            ${{ steps.names.outputs.image_name }}:${{ env.TAG_SUFFIX }}
            ${{ steps.names.outputs.image_name }}:cpu-${{ github.sha }}
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.revision=${{ github.sha }}
            org.opencontainers.image.description=CPU-only Ollama build (ggml)

  preload-and-push:
    needs: build-and-push
    runs-on: ubuntu-latest
    env:
      IMAGE_NAME: ${{ needs.build-and-push.outputs.image_name }}
      TAG_SUFFIX: ${{ needs.build-and-push.outputs.tag_suffix }}
      PRELOAD_SUFFIX: ${{ needs.build-and-push.outputs.preload_suffix }}
      MODEL_PULL: "llama3:8b"
      MODEL_TARGET: "llama3-8b-local"
    steps:
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull base image
        run: docker pull "${IMAGE_NAME}:${TAG_SUFFIX}"

      - name: Preload model into image
        run: |
          docker rm -f ollama-preload 2>/dev/null || true
          docker run -d --name ollama-preload "${IMAGE_NAME}:${TAG_SUFFIX}" serve
          docker exec ollama-preload ollama pull "${MODEL_PULL}"
          docker exec ollama-preload ollama cp "${MODEL_PULL}" "${MODEL_TARGET}"
          docker stop ollama-preload
          docker commit ollama-preload "${IMAGE_NAME}:${PRELOAD_SUFFIX}"
          docker tag "${IMAGE_NAME}:${PRELOAD_SUFFIX}" "${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}"
          if [ "${TAG_SUFFIX}" = "cpu-latest" ]; then
            docker tag "${IMAGE_NAME}:${PRELOAD_SUFFIX}" "${IMAGE_NAME}:cpu-preloaded"
          fi

      - name: Push preloaded image
        run: |
          docker push "${IMAGE_NAME}:${PRELOAD_SUFFIX}"
          docker push "${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}"
          if [ "${TAG_SUFFIX}" = "cpu-latest" ]; then
            docker push "${IMAGE_NAME}:cpu-preloaded"
          fi

      - name: Cleanup local images/containers
        if: always()
        run: |
          docker rm -f ollama-preload 2>/dev/null || true
          docker rmi "${IMAGE_NAME}:${PRELOAD_SUFFIX}" "${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}" "${IMAGE_NAME}:cpu-preloaded" 2>/dev/null || true
