name: Publish Ollama CPU image

on:
  workflow_dispatch:
    inputs:
      ref:
        description: "ollama git ref (tag/branch/sha) to build"
        required: false
        default: "main"
      tag:
        description: "image tag suffix (e.g., cpu-20250216; default cpu-latest)"
        required: false
        default: "cpu-latest"
      bundle_url:
        description: "Optional URL to a .ollama model bundle (e.g., llama3-8b-local.ollama) to bake into the preloaded image"
        required: false
        default: ""
      bundle_sha256:
        description: "Optional SHA256 for the bundle to verify integrity"
        required: false
        default: ""
  push:
    branches: [ main ]
    paths:
      - "docker/ollama/**"
      - ".github/workflows/ollama-image.yml"

permissions:
  contents: read
  packages: write

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    outputs:
      image_name: ${{ steps.names.outputs.image_name }}
      tag_suffix: ${{ env.TAG_SUFFIX }}
      preload_suffix: ${{ env.PRELOAD_SUFFIX }}
    env:
      OLLAMA_REF: ${{ github.event.inputs.ref || 'main' }}
      TAG_SUFFIX: ${{ github.event.inputs.tag || 'cpu-latest' }}
      SOURCE_DIR: /tmp/ollama-source
      PRELOAD_SUFFIX: cpu-preloaded-${{ github.event.inputs.tag || 'cpu-latest' }}
    steps:
      - name: Checkout repo (for Dockerfile)
        uses: actions/checkout@v4

      - name: Compute image name (lowercase owner)
        id: names
        run: |
          owner="${{ github.repository_owner }}"
          owner_lc="$(echo "$owner" | tr '[:upper:]' '[:lower:]')"
          echo "image_name=ghcr.io/${owner_lc}/ollama-local" >> "$GITHUB_OUTPUT"

      - name: Clone upstream ollama
        run: |
          git clone --depth 1 --branch "${OLLAMA_REF}" https://github.com/ollama/ollama.git "${SOURCE_DIR}"

      - name: Copy CPU Dockerfile into source
        run: |
          cp docker/ollama/Dockerfile "${SOURCE_DIR}/Dockerfile.cpu"

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: ${{ env.SOURCE_DIR }}
          file: ${{ env.SOURCE_DIR }}/Dockerfile.cpu
          push: true
          tags: |
            ${{ steps.names.outputs.image_name }}:${{ env.TAG_SUFFIX }}
            ${{ steps.names.outputs.image_name }}:cpu-${{ github.sha }}
          labels: |
            org.opencontainers.image.source=${{ github.repository }}
            org.opencontainers.image.revision=${{ github.sha }}
            org.opencontainers.image.description=CPU-only Ollama build (ggml)

  preload-and-push:
    needs: build-and-push
    runs-on: ubuntu-latest
    env:
      IMAGE_NAME: ${{ needs.build-and-push.outputs.image_name }}
      TAG_SUFFIX: ${{ needs.build-and-push.outputs.tag_suffix }}
      PRELOAD_SUFFIX: ${{ needs.build-and-push.outputs.preload_suffix }}
      MODEL_PULL: "llama3:8b"
      MODEL_TARGET: "llama3-8b-local"
      BUNDLE_URL: ${{ github.event.inputs.bundle_url || '' }}
      BUNDLE_SHA256: ${{ github.event.inputs.bundle_sha256 || '' }}
    steps:
      - name: Checkout repo (for helper script)
        uses: actions/checkout@v4

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Download bundle (if provided)
        if: env.BUNDLE_URL != ''
        run: |
          curl -L "$BUNDLE_URL" -o /tmp/model.ollama
          if [ -n "$BUNDLE_SHA256" ]; then
            echo "$BUNDLE_SHA256  /tmp/model.ollama" | sha256sum -c -
          fi

      - name: Build preloaded image from bundle
        if: env.BUNDLE_URL != ''
        run: |
          pwsh -NoProfile -File scripts/ollama-executor/build-preloaded-image.ps1 `
            -BaseImage "${IMAGE_NAME}:${TAG_SUFFIX}" `
            -PreloadedTag "${IMAGE_NAME}:cpu-preloaded" `
            -ModelBundlePath /tmp/model.ollama `
            -BundleSha256 "$BUNDLE_SHA256" `
            -ImportTag "${MODEL_TARGET}" `
            -TargetTag "${MODEL_TARGET}" `
            -ExtraTags @("${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}", "${IMAGE_NAME}:${PRELOAD_SUFFIX}") `
            -Push

      - name: Fallback preload via pull (no bundle provided)
        if: env.BUNDLE_URL == ''
        run: |
          docker rm -f ollama-preload 2>/dev/null || true
          docker pull "${IMAGE_NAME}:${TAG_SUFFIX}"
          docker run -d --name ollama-preload "${IMAGE_NAME}:${TAG_SUFFIX}" serve
          docker exec ollama-preload ollama pull "${MODEL_PULL}"
          docker exec ollama-preload ollama cp "${MODEL_PULL}" "${MODEL_TARGET}"
          docker stop ollama-preload
          docker commit ollama-preload "${IMAGE_NAME}:cpu-preloaded"
          docker tag "${IMAGE_NAME}:cpu-preloaded" "${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}"
          docker tag "${IMAGE_NAME}:cpu-preloaded" "${IMAGE_NAME}:${PRELOAD_SUFFIX}"
          docker push "${IMAGE_NAME}:cpu-preloaded"
          docker push "${IMAGE_NAME}:cpu-preloaded-${GITHUB_SHA}"
          docker push "${IMAGE_NAME}:${PRELOAD_SUFFIX}"

      - name: Cleanup local images/containers
        if: always()
        run: |
          docker rm -f ollama-preload 2>/dev/null || true
